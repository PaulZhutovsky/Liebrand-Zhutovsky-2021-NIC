{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import (StratifiedKFold, RepeatedStratifiedKFold, \n",
    "                                     KFold, RepeatedKFold)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (roc_auc_score, balanced_accuracy_score, recall_score, \n",
    "                             brier_score_loss, mean_absolute_error, mean_squared_error, \n",
    "                             median_absolute_error, r2_score)\n",
    "from sklearn.utils.extmath import row_norms\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(file_path, dtype=np.float):\n",
    "    return np.array(nib.load(file_path).dataobj, dtype=dtype)\n",
    "\n",
    "\n",
    "def load_scalar_momenta(scl_mom_folder, patient_ids, mask):\n",
    "    X_gm_scl = np.zeros((patient_ids.size, mask.sum()))\n",
    "    X_wm_scl = np.zeros((patient_ids.size, mask.sum()))\n",
    "    \n",
    "    print('Loading Scalar Momenta...')\n",
    "    for i_pat, patient_id, in enumerate(tqdm(patient_ids)):\n",
    "        tmp = load_nifti(osp.join(scl_mom_folder, 'a_rc1{}T1.nii.gz'.format(patient_id)))\n",
    "        X_gm_scl[i_pat] = tmp[..., 0][mask]\n",
    "        X_wm_scl[i_pat] = tmp[..., 1][mask]\n",
    "    return X_gm_scl, X_wm_scl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Scalar Momenta...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e02568cd0a64c448fa0d52d7ec56b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "regress_covariates = True\n",
    "\n",
    "if regress_covariates:\n",
    "    suffix_cov_reg = 'with_covariate_regr'\n",
    "else:\n",
    "    suffix_cov_reg = 'without_covariate_regr'\n",
    "\n",
    "project_folder = '/data/shared/OCDDBSpred'\n",
    "palm_analysis =  osp.join(project_folder, 'data', 'analysis_data', \n",
    "                          'cat12_analysis', 'palm_analysis_s8')\n",
    "scalar_momenta_folder = osp.join(project_folder, 'data', 'preprocessed')\n",
    "regr_folder = osp.join(palm_analysis, 'ybocs_1y')\n",
    "clf_folder = osp.join(palm_analysis, 'responders_vs_nonresponders')\n",
    "\n",
    "# The data/masks in whole_brain/ROI folders are the same for classification or regression\n",
    "whole_brain_folder = osp.join(regr_folder, 'whole_brain')\n",
    "roi_folder = osp.join(clf_folder, 'ROI')\n",
    "\n",
    "gm_file = osp.join(whole_brain_folder, 's8gm_all.nii')\n",
    "wm_file = osp.join(whole_brain_folder, 's8wm_all.nii')\n",
    "\n",
    "mask_scl_mom = load_nifti(osp.join(project_folder, 'data', 'analysis_data', 'masks', \n",
    "                                   'mask_overall_new.nii.gz'), dtype=bool)\n",
    "\n",
    "mask_gm = load_nifti(osp.join(whole_brain_folder, 'mask_s8gm.nii'), dtype=bool)\n",
    "mask_wm = load_nifti(osp.join(whole_brain_folder, 'mask_s8wm.nii'), dtype=bool)\n",
    "\n",
    "mask_na = load_nifti(osp.join(roi_folder, 'NucleusAccumbens.nii'), dtype=bool)\n",
    "mask_atr = load_nifti(osp.join(roi_folder, 'AnteriorThalamicRadiation.nii'), dtype=bool)\n",
    "\n",
    "gm_3d = load_nifti(gm_file)\n",
    "wm_3d = load_nifti(wm_file)\n",
    "\n",
    "X_gm_whole = gm_3d[mask_gm, :].T.copy()\n",
    "X_wm_whole = wm_3d[mask_wm, :].T.copy()\n",
    "\n",
    "X_gm_na = gm_3d[mask_na, :].T.copy()\n",
    "X_wm_atr = wm_3d[mask_atr, :].T.copy()\n",
    "\n",
    "del gm_3d, wm_3d\n",
    "\n",
    "df_regr_whole_brain = pd.read_csv(osp.join(whole_brain_folder, 'design', 'design.csv'))\n",
    "df_clf_roi = pd.read_csv(osp.join(roi_folder, 'design', 'design.csv'))\n",
    "assert (df_regr_whole_brain.Patient == df_clf_roi.Patient).all()\n",
    "\n",
    "X_gm_scl, X_wm_scl = load_scalar_momenta(scalar_momenta_folder, \n",
    "                                         df_regr_whole_brain.Patient.values, \n",
    "                                         mask_scl_mom)\n",
    "\n",
    "covariate_variables = ['age_baseline', 'gender_1F_0M', 'cat12_TIV_vol_cm3', \n",
    "                       'scanner_A', 'scanner_B', 'scanner_C', 'scanner_D', 'scanner_E']\n",
    "# It was verified manually that the same (!) covariate values were present both in \n",
    "# df_clf_roi and df_regr_whole_brain, except for scan type_1 which had to be dropped for \n",
    "# the responders vs non-responders design since it would have lead to a singular matrix \n",
    "# (sum scan_types == responders + non-responders)\n",
    "# will be used below in the covariate regression\n",
    "idx_covariate_demean = [0, 1, 2]\n",
    "\n",
    "C = df_regr_whole_brain[covariate_variables].values\n",
    "\n",
    "# Y-BOCS is scaled between 0 and 1 (maximum value is 40)\n",
    "regr_scaling_factor = 40\n",
    "y_regr = df_regr_whole_brain.YBOCS_1y.values / regr_scaling_factor\n",
    "y_clf = df_clf_roi.responder.values \n",
    "ybocs_pre = df_regr_whole_brain.YBOCS_baseline.values / regr_scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_features(n_ftrs, perc_chosen):\n",
    "    return int(round(perc_chosen * n_ftrs))\n",
    "\n",
    "\n",
    "def clf_feature_selection(X, y, perc_chosen=0.1):\n",
    "    # verified against scikit-learns implementation\n",
    "    n = y.size\n",
    "    # 2 because of 2 classes in y for degrees of freedom (df) calculation\n",
    "    df = n - 2\n",
    "    to_pick = get_n_features(X.shape[1], perc_chosen)\n",
    "    id_grp1 = (y == 1).astype(np.float)\n",
    "    id_grp0 = (y == 0).astype(np.float)\n",
    "    n1 = id_grp1.sum(dtype=np.int)\n",
    "    n0 = n - n1\n",
    "    # instead of dividing by n1/n0 and the multiplying by it again\n",
    "    mu_grp1 = id_grp1.dot(X)\n",
    "    mu_grp0 = id_grp0.dot(X)\n",
    "    mu_all = (mu_grp1 + mu_grp0) \n",
    "    mu_all /= n\n",
    "    mu_grp1 /= n1\n",
    "    mu_grp0 /= n0\n",
    "    \n",
    "    # also no normalization as before because of the same reason as before\n",
    "    sqr_var_grp1 = (X - mu_grp1) ** 2\n",
    "    var_grp1 = id_grp1.dot(sqr_var_grp1)\n",
    "    \n",
    "    sqr_var_grp0 = (X - mu_grp0) ** 2\n",
    "    var_grp0 = id_grp0.dot(sqr_var_grp0)\n",
    "    var_all = var_grp0 + var_grp1\n",
    "    \n",
    "    fisher_score = (n1 * (mu_grp1 - mu_all) ** 2 + n0 * (mu_grp0 - mu_all) ** 2) \n",
    "    fisher_score /= var_all\n",
    "    fisher_score *= df\n",
    "    return np.argsort(fisher_score)[-to_pick:]\n",
    "\n",
    "\n",
    "def regr_feature_selection(X, y, perc_chosen=0.1):\n",
    "    n = y.size\n",
    "    to_pick = get_n_features(X.shape[1], perc_chosen)\n",
    "    \n",
    "    # correlation calculation verified (multiple times...)\n",
    "    # the first formula of Pearson correlation from wikipedia\n",
    "    y = y - y.mean()\n",
    "    id_all = np.ones(X.shape[0]) / n\n",
    "    X_means = id_all.dot(X)\n",
    "    X_norms = np.sqrt(row_norms(X.T, squared=True) - n * X_means ** 2)\n",
    "    \n",
    "    r = y.dot(X)\n",
    "    r /= X_norms\n",
    "    r /= np.linalg.norm(y)\n",
    "    return np.argsort(np.abs(r))[-to_pick:]\n",
    "\n",
    "\n",
    "def feature_selection(analysis_type, X, y, perc_chosen=0.1):\n",
    "    if analysis_type == 'regression':\n",
    "        return regr_feature_selection(X, y, perc_chosen=perc_chosen)\n",
    "    else:\n",
    "        return clf_feature_selection(X, y, perc_chosen=perc_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv(analysis_type='classification', cv_scale='outer', random_state=42):\n",
    "    \n",
    "    if analysis_type == 'classification' and cv_scale == 'outer':\n",
    "        # 10x5-fold CV - stratified\n",
    "        return RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=random_state)\n",
    "    \n",
    "    elif analysis_type == 'classification' and cv_scale == 'inner':\n",
    "        # 5-fold CV - stratified\n",
    "        return StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    elif analysis_type == 'regression' and cv_scale == 'outer':\n",
    "        # 10x5-fold CV\n",
    "        return RepeatedKFold(n_splits=5, n_repeats=10, random_state=random_state)\n",
    "    \n",
    "    else:\n",
    "        # 5-fold CV\n",
    "        return KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    \n",
    "def get_ml_model(analysis_type):\n",
    "    if analysis_type == 'classification':\n",
    "        return SVC(kernel='linear', C=1.0, probability=True, class_weight='balanced', \n",
    "                   tol=1e-4)\n",
    "    else:\n",
    "        return SVR(kernel='linear', C=1.0, tol=1e-4)\n",
    "    \n",
    "    \n",
    "def score_inner(model, X, y, analysis_type):\n",
    "    if analysis_type == 'classification':\n",
    "        y_score = model.predict_proba(X)[:, 1]\n",
    "        return roc_auc_score(y_true=y, y_score=y_score)\n",
    "    else:\n",
    "        y_pred = model.predict(X)\n",
    "        # negated here so that we can take the maximum to get the best performing \n",
    "        # hyperparameters in both classification and regression\n",
    "        return -mean_absolute_error(y_true=y, y_pred=y_pred)\n",
    "    \n",
    "    \n",
    "def score_outer(model, X, y, analysis_type, regr_scaling_factor=1):\n",
    "    y_pred = model.predict(X)\n",
    "    if analysis_type == 'classification':\n",
    "        y_score = model.predict_proba(X)[:, 1]\n",
    "        auc = roc_auc_score(y_true=y, y_score=y_score)\n",
    "        acc = balanced_accuracy_score(y_true=y, y_pred=y_pred)\n",
    "        sens = recall_score(y_true=y, y_pred=y_pred, pos_label=1)\n",
    "        spec = recall_score(y_true=y, y_pred=y_pred, pos_label=0)\n",
    "        brier = brier_score_loss(y_true=y, y_prob=y_score)\n",
    "        score_dict = {'ACC': acc, 'AUC': auc, 'SENS': sens, 'SPEC': spec, 'Brier': brier}\n",
    "    else:\n",
    "        # done like this on purpose to create a copy and not change anything weird in the main code\n",
    "        # allows to express all errors in the original Y-BOCS scale (0 to 40)\n",
    "        y = y * regr_scaling_factor\n",
    "        y_pred = y_pred * regr_scaling_factor\n",
    "        mae = mean_absolute_error(y_true=y, y_pred=y_pred)\n",
    "        mse = mean_squared_error(y_true=y, y_pred=y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        medae = median_absolute_error(y_true=y, y_pred=y_pred)\n",
    "        r2 = r2_score(y_true=y, y_pred=y_pred)\n",
    "        r = np.corrcoef(y, y_pred)[0, 1]\n",
    "        score_dict = {'MAE': mae, 'MedAE': medae, 'MSE': mse, 'RMSE': rmse, 'R2': r2, 'r': r}\n",
    "    return score_dict\n",
    "\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, scaler\n",
    "\n",
    "\n",
    "def denoise_data(X_train, X_test, C_train, C_test):\n",
    "    coefs, _, _, _ = np.linalg.lstsq(C_train, X_train, rcond=None)\n",
    "    X_train -= C_train.dot(coefs)\n",
    "    X_test -= C_test.dot(coefs)\n",
    "    return X_train, X_test, coefs\n",
    "\n",
    "\n",
    "def one_cv_run(X_train, y_train, C_train, X_test, y_test, C_test, sel_ftrs, idx_covariate_demean, \n",
    "               regress_covariates, analysis_type, additional_feature=None):\n",
    "    if regress_covariates:\n",
    "        (C_train[:, idx_covariate_demean], C_test[:, idx_covariate_demean], _) = scale_data(\n",
    "            C_train[:, idx_covariate_demean], C_test[:, idx_covariate_demean])\n",
    "        X_train, X_test, _ = denoise_data(X_train, X_test, C_train, C_test)\n",
    "\n",
    "    # only do feature selection if we are actually selecting features\n",
    "    if sel_ftrs < 1:\n",
    "        id_selected = feature_selection(analysis_type=analysis_type, \n",
    "                                        X=X_train, \n",
    "                                        y=y_train, \n",
    "                                        perc_chosen=sel_ftrs)\n",
    "        X_train, X_test = X_train[:, id_selected], X_test[:, id_selected]\n",
    "    \n",
    "    X_train = np.column_stack((X_train, additional_feature['train']))\n",
    "    X_test = np.column_stack((X_test, additional_feature['test']))\n",
    "        \n",
    "    X_train, X_test, _ = scale_data(X_train, X_test)\n",
    "\n",
    "    ml_model = get_ml_model(analysis_type)\n",
    "    ml_model.fit(X_train, y_train)\n",
    "    \n",
    "    # y_test hasn't be touched but will be passed through \n",
    "    return X_test, y_test, ml_model,\n",
    "\n",
    "\n",
    "def get_data_types_names():\n",
    "    return ['whole-brain:GMV', 'whole-brain:WMV', 'whole-brain:GMV+WMV', 'ROI:NAc', 'ROI:ATR', 'ROI:NAc+ATR',\n",
    "            'SclMom:GM+WM']\n",
    "\n",
    "\n",
    "def get_perf_metrics(analysis_type):\n",
    "    if analysis_type == 'classification':\n",
    "        perf_metrics = ['ACC', 'AUC', 'SENS', 'SPEC', 'Brier'] \n",
    "    else:\n",
    "        perf_metrics = ['MAE', 'MedAE', 'MSE', 'RMSE', 'R2', 'r']\n",
    "    return perf_metrics\n",
    "\n",
    "\n",
    "def get_df_scores(analysis_type):\n",
    "    index = get_data_types_names()\n",
    "    stats = ['mean', 'SD']\n",
    "    \n",
    "    perf_metrics = get_perf_metrics(analysis_type)\n",
    "    multi_col_index = pd.MultiIndex.from_product([perf_metrics, stats])\n",
    "    df = pd.DataFrame(index=index, columns=multi_col_index)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_df_cv(analysis_type):\n",
    "    perf_metrics = get_perf_metrics(analysis_type)\n",
    "    if analysis_type == 'classification':\n",
    "        df = pd.DataFrame(columns=perf_metrics)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=perf_metrics)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "whole-brain\n",
      "GMV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4017f805060042748b76783c2885fd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WMV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0061487b7a480fba05df57a963fd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GMV+WMV\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8d109b127745c2ad06dc5a40646ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROI\n",
      "NAc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac40844809a742969e59d39fd62e20b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ATR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b91a47eb09254e17a45beb050a4e5b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAc+ATR\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1ba7106f8542ea9a2826ffcd203d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SclMom\n",
      "GM+WM\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c232ea4a1c4664b0b43ac86f36f9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "classification\n",
      "                          ACC                 AUC                SENS  \\\n",
      "                         mean        SD      mean        SD      mean   \n",
      "whole-brain:GMV      0.482143  0.102543   0.46781   0.12418  0.567619   \n",
      "whole-brain:WMV      0.448952  0.145226   0.42227  0.172875  0.575238   \n",
      "whole-brain:GMV+WMV     0.481  0.155608  0.433222  0.170585  0.606667   \n",
      "ROI:NAc              0.572952  0.132347  0.542746  0.213211  0.621905   \n",
      "ROI:ATR              0.428619  0.148593  0.509286  0.201441  0.471905   \n",
      "ROI:NAc+ATR          0.485714   0.14566  0.480556  0.161548  0.541429   \n",
      "SclMom:GM                 NaN       NaN       NaN       NaN       NaN   \n",
      "SclMom:WM                 NaN       NaN       NaN       NaN       NaN   \n",
      "SclMom:GM+WM         0.515238  0.102409  0.546016  0.136442   0.56381   \n",
      "\n",
      "                                   SPEC               Brier            0.001  \\\n",
      "                           SD      mean        SD      mean         SD         \n",
      "whole-brain:GMV      0.199632  0.396667  0.195673   0.32089  0.0623538    10   \n",
      "whole-brain:WMV      0.232707  0.322667  0.215756  0.329088  0.0910338     8   \n",
      "whole-brain:GMV+WMV  0.227115  0.355333  0.193969  0.321625  0.0846757     7   \n",
      "ROI:NAc              0.196199     0.524  0.200005  0.253945  0.0297484   NaN   \n",
      "ROI:ATR              0.191608  0.385333  0.240196  0.260579  0.0310535   NaN   \n",
      "ROI:NAc+ATR          0.176531      0.43  0.224088   0.27012  0.0448919   NaN   \n",
      "SclMom:GM                 NaN       NaN       NaN       NaN        NaN   NaN   \n",
      "SclMom:WM                 NaN       NaN       NaN       NaN        NaN   NaN   \n",
      "SclMom:GM+WM         0.172126  0.466667  0.185164  0.292126  0.0634194    13   \n",
      "\n",
      "                    0.005 0.01 0.05  0.1 0.15  0.2  1.0 random_seed  \n",
      "                                                                     \n",
      "whole-brain:GMV         6    8    3    9  NaN  NaN   14  1585128917  \n",
      "whole-brain:WMV         4    4    8    8  NaN  NaN   18  1585128917  \n",
      "whole-brain:GMV+WMV     1    4    9   10  NaN  NaN   19  1585128917  \n",
      "ROI:NAc               NaN   23    6    3    2    5   11  1585128917  \n",
      "ROI:ATR               NaN    5    7    7   13    8   10  1585128917  \n",
      "ROI:NAc+ATR           NaN   10    9    7   12    3    9  1585128917  \n",
      "SclMom:GM             NaN  NaN  NaN  NaN  NaN  NaN  NaN  1585128917  \n",
      "SclMom:WM             NaN  NaN  NaN  NaN  NaN  NaN  NaN  1585128917  \n",
      "SclMom:GM+WM           11   10    5    6  NaN  NaN    5  1585128917  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'whole-brain': {'GMV': X_gm_whole, \n",
    "                             'WMV': X_wm_whole, \n",
    "                             'GMV+WMV': np.column_stack((X_gm_whole, X_wm_whole))},\n",
    "             'ROI': {'NAc': X_gm_na, \n",
    "                     'ATR': X_wm_atr, \n",
    "                     'NAc+ATR': np.column_stack((X_gm_na, X_wm_atr))},\n",
    "             'SclMom': {'GM+WM': np.column_stack((X_gm_scl, X_wm_scl))}}\n",
    "\n",
    "dtype_names = get_data_types_names()\n",
    "\n",
    "analysis_dict = {'classification': y_clf,\n",
    "                 'regression': y_regr}\n",
    "\n",
    "perc_chosen = {'whole-brain': [0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
    "               'ROI': [0.01, 0.05, 0.1, 0.15, 0.20, 1],\n",
    "               'SclMom': [0.001, 0.005, 0.01, 0.05, 0.1, 1]}\n",
    "\n",
    "df_perc_chosen = pd.DataFrame(index=dtype_names, \n",
    "                              columns=[0.001, 0.005, 0.01, 0.05, 0.1, 0.15, 0.20, 1])\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for analysis_type, y in analysis_dict.items():\n",
    "    print(analysis_type)\n",
    "    \n",
    "    random_state_outer = int(time())\n",
    "    random_state_inner = random_state_outer + 100\n",
    "    df_score = get_df_scores(analysis_type)\n",
    "\n",
    "    for data_scale, X_dict in data_dict.items():\n",
    "        print(data_scale)\n",
    "        \n",
    "        for data_type, X in X_dict.items():\n",
    "            print(data_type)\n",
    "            \n",
    "            cv_outer = get_cv(analysis_type=analysis_type, cv_scale='outer', \n",
    "                              random_state=random_state_outer)\n",
    "            \n",
    "            chosen_probabilities = perc_chosen[data_scale]\n",
    "            \n",
    "            df_cv = get_df_cv(analysis_type)\n",
    "            picked_probs = pd.Series(data=0, index=chosen_probabilities)\n",
    "\n",
    "            for i_cv_outer, (id_train, id_test) in enumerate(tqdm(cv_outer.split(X, y))):\n",
    "                X_train, X_test = X[id_train], X[id_test]\n",
    "                C_train, C_test = C[id_train], C[id_test]\n",
    "                y_train, y_test = y[id_train], y[id_test]\n",
    "                ybocs_pre_train, ybocs_pre_test = ybocs_pre[id_train], ybocs_pre[id_test]\n",
    "                ybocs_pre_outer = {'train': ybocs_pre_train,\n",
    "                                   'test': ybocs_pre_test}\n",
    "                \n",
    "                scores_grid_search = np.zeros((5, len(chosen_probabilities)))\n",
    "            \n",
    "                for i_ftrs, sel_ftrs in enumerate(chosen_probabilities):\n",
    "                    cv_inner = get_cv(analysis_type=analysis_type, cv_scale='inner', \n",
    "                                      random_state=random_state_inner)\n",
    "                    \n",
    "                    for i_cv_inner, (id_train_inner, id_test_inner) in enumerate(cv_inner.split(X_train, \n",
    "                                                                                                y_train)):\n",
    "                        X_train_inner, X_test_inner = (X_train[id_train_inner], \n",
    "                                                       X_train[id_test_inner])\n",
    "                        C_train_inner, C_test_inner = (C_train[id_train_inner], \n",
    "                                                       C_train[id_test_inner])\n",
    "                        y_train_inner, y_test_inner = (y_train[id_train_inner], \n",
    "                                                       y_train[id_test_inner])\n",
    "                        ybocs_pre_train_inner, ybocs_pre_test_inner = (ybocs_pre_train[id_train_inner],\n",
    "                                                                       ybocs_pre_train[id_test_inner])\n",
    "                        \n",
    "                        ybocs_pre_inner = {'train': ybocs_pre_train_inner,\n",
    "                                           'test': ybocs_pre_test_inner}\n",
    "                        \n",
    "                        X_test_inner, y_test_inner, ml_model = one_cv_run(X_train_inner, \n",
    "                                                                          y_train_inner, \n",
    "                                                                          C_train_inner, \n",
    "                                                                          X_test_inner, \n",
    "                                                                          y_test_inner, \n",
    "                                                                          C_test_inner, \n",
    "                                                                          sel_ftrs, \n",
    "                                                                          idx_covariate_demean, \n",
    "                                                                          regress_covariates, \n",
    "                                                                          analysis_type,\n",
    "                                                                          additional_feature=ybocs_pre_inner)\n",
    "    \n",
    "                        \n",
    "                        scores_grid_search[i_cv_inner, i_ftrs] = score_inner(ml_model, \n",
    "                                                                             X_test_inner, \n",
    "                                                                             y_test_inner, \n",
    "                                                                             analysis_type)\n",
    "                \n",
    "                mean_scores_gsearch = scores_grid_search.mean(axis=0)\n",
    "                id_best = mean_scores_gsearch.argmax()\n",
    "                best_prob = chosen_probabilities[id_best]\n",
    "                picked_probs[best_prob] += 1\n",
    "                \n",
    "                X_test, y_test, ml_model = one_cv_run(X_train, \n",
    "                                                      y_train, \n",
    "                                                      C_train, \n",
    "                                                      X_test, \n",
    "                                                      y_test, \n",
    "                                                      C_test, \n",
    "                                                      best_prob, \n",
    "                                                      idx_covariate_demean, \n",
    "                                                      regress_covariates, \n",
    "                                                      analysis_type, \n",
    "                                                      additional_feature=ybocs_pre_outer)\n",
    "                \n",
    "                df_cv = df_cv.append(score_outer(ml_model, X_test, y_test, analysis_type, \n",
    "                                                 regr_scaling_factor=regr_scaling_factor), ignore_index=True)\n",
    "            \n",
    "            df_perc_chosen.loc[\"{}:{}\".format(data_scale, data_type)] = picked_probs\n",
    "            \n",
    "            mean_cv = df_cv.mean()\n",
    "            sd_cv = df_cv.std()\n",
    "            index_cv = mean_cv.index\n",
    "            assert (index_cv == sd_cv.index).all()\n",
    "            \n",
    "            df_cv.to_csv('results_cv_{}_{}_{}_{}.csv'.format(analysis_type, \n",
    "                                                             data_type, \n",
    "                                                             data_scale, \n",
    "                                                             suffix_cov_reg), index=False)\n",
    "            \n",
    "            if 'r' in index_cv:\n",
    "                r = df_cv['r'].values\n",
    "                rtoz = np.arctanh(r)\n",
    "                mean_r = np.tanh(rtoz.mean())\n",
    "                sd_r = np.tanh(rtoz.std())\n",
    "                mean_cv.loc['r'] = mean_r\n",
    "                sd_cv.loc['r'] = sd_r\n",
    "            \n",
    "            df_score.loc['{}:{}'.format(data_scale, data_type), \n",
    "                         (index_cv, 'mean')] = mean_cv.values\n",
    "            df_score.loc['{}:{}'.format(data_scale, data_type), \n",
    "                         (index_cv, 'SD')] = sd_cv.values\n",
    "    \n",
    "    df_score[df_perc_chosen.columns] = df_perc_chosen\n",
    "    df_score['random_seed'] = random_state_outer\n",
    "    df_score.to_csv('results_{}_{}.csv'.format(analysis_type, suffix_cov_reg))\n",
    "    results_dict[analysis_type] = df_score\n",
    "    print()\n",
    "    print(analysis_type)\n",
    "    print(df_score)    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE: ', np.mean(np.abs(y_regr - y_regr.mean())))\n",
    "print('MedAE: ', np.median(np.abs(y_regr - y_regr.mean())))\n",
    "print('MSE: ', np.mean((y_regr - y_regr.mean()) ** 2))\n",
    "print('RMSE: ', np.sqrt(np.mean((y_regr - y_regr.mean()) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE: ', np.mean(np.abs(y_regr * 100 - y_regr.mean() * 100)))\n",
    "print('MedAE: ', np.median(np.abs(y_regr * 100 - y_regr.mean() * 100)))\n",
    "print('MSE: ', np.mean((y_regr * 100 - y_regr.mean() * 100) ** 2))\n",
    "print('RMSE: ', np.sqrt(np.mean((y_regr * 100 - y_regr.mean() * 100) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running permutation tests only for the classification case with ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'NAc': X_gm_na, \n",
    "             'ATR': X_wm_atr, \n",
    "             'NAc+ATR': np.column_stack((X_gm_na, X_wm_atr))}\n",
    "\n",
    "analysis_type = 'classification'\n",
    "chosen_probabilities = [0.01, 0.05, 0.1, 0.15, 0.20, 1]\n",
    "n_perm = 1000\n",
    "perf_metrics = get_perf_metrics(analysis_type)\n",
    "\n",
    "print('Running permutation tests:')\n",
    "\n",
    "for roi_name, X in data_dict.items():\n",
    "    print(roi_name)\n",
    "    \n",
    "    df_perm = pd.DataFrame(columns=perf_metrics)\n",
    "    y_perm = y_clf.copy()\n",
    "    seed = int(time())\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    for i_perm in tqdm(range(n_perm)):\n",
    "        y_perm = rng.permutation(y_perm)\n",
    "        \n",
    "        random_state_outer = seed + 100\n",
    "        random_state_inner = random_state_outer + 100\n",
    "        df_score = get_df_scores(analysis_type) \n",
    "        cv_outer = get_cv(analysis_type=analysis_type, cv_scale='outer', \n",
    "                          random_state=random_state_outer)\n",
    "                       \n",
    "        df_cv = get_df_cv(analysis_type)\n",
    "        \n",
    "        for i_cv_outer, (id_train, id_test) in enumerate(cv_outer.split(X, y_perm)):\n",
    "            X_train, X_test = X[id_train], X[id_test]\n",
    "            C_train, C_test = C[id_train], C[id_test]\n",
    "            y_train, y_test = y_perm[id_train], y_perm[id_test]\n",
    "\n",
    "            scores_grid_search = np.zeros((5, len(chosen_probabilities)))\n",
    "            \n",
    "            for i_ftrs, sel_ftrs in enumerate(chosen_probabilities):\n",
    "                cv_inner = get_cv(analysis_type=analysis_type, cv_scale='inner', \n",
    "                                  random_state=random_state_inner)\n",
    "                    \n",
    "                for i_cv_inner, (id_train_inner, id_test_inner) in enumerate(cv_inner.split(X_train, \n",
    "                                                                                                y_train)):\n",
    "                    X_train_inner, X_test_inner = (X_train[id_train_inner], \n",
    "                                                   X_train[id_test_inner])\n",
    "                    C_train_inner, C_test_inner = (C_train[id_train_inner], \n",
    "                                                   C_train[id_test_inner])\n",
    "                    y_train_inner, y_test_inner = (y_train[id_train_inner], \n",
    "                                                   y_train[id_test_inner])\n",
    "                        \n",
    "                    X_test_inner, y_test_inner, ml_model = one_cv_run(X_train_inner, \n",
    "                                                                      y_train_inner, \n",
    "                                                                      C_train_inner, \n",
    "                                                                      X_test_inner, \n",
    "                                                                      y_test_inner, \n",
    "                                                                      C_test_inner, \n",
    "                                                                      sel_ftrs, \n",
    "                                                                      idx_covariate_demean, \n",
    "                                                                      regress_covariates, \n",
    "                                                                      analysis_type)\n",
    "    \n",
    "                        \n",
    "                    scores_grid_search[i_cv_inner, i_ftrs] = score_inner(ml_model, \n",
    "                                                                         X_test_inner, \n",
    "                                                                         y_test_inner, \n",
    "                                                                         analysis_type)\n",
    "            \n",
    "            mean_scores_gsearch = scores_grid_search.mean(axis=0)\n",
    "            id_best = mean_scores_gsearch.argmax()\n",
    "            best_prob = chosen_probabilities[id_best]\n",
    "                \n",
    "            X_test, y_test, ml_model = one_cv_run(X_train, \n",
    "                                                  y_train, \n",
    "                                                  C_train, \n",
    "                                                  X_test, \n",
    "                                                  y_test, \n",
    "                                                  C_test, \n",
    "                                                  best_prob, \n",
    "                                                  idx_covariate_demean, \n",
    "                                                  regress_covariates, \n",
    "                                                  analysis_type)\n",
    "                \n",
    "            df_cv = df_cv.append(score_outer(ml_model, X_test, y_test, analysis_type), \n",
    "                                 ignore_index=True)\n",
    "                        \n",
    "        mean_cv = df_cv.mean()\n",
    "        df_perm = df_perm.append(mean_cv, ignore_index=True)\n",
    "\n",
    "    df_perm.to_csv('results_perm_{}_{}.csv'.format(analysis_type, roi_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_permutation_pvalue(df_real, df_perm, metric_to_use='AUC'):\n",
    "    real_value = df_real[metric_to_use, 'mean']\n",
    "    perm_values = df_perm[metric_to_use].to_numpy()\n",
    "    print('Real value: {:0.4f}'.format(real_value))\n",
    "    print('Permutation values: mean: {:0.4f}; min: {:0.4f}; max: {:0.4f}'.format(perm_values.mean(),\n",
    "                                                                                 perm_values.min(),\n",
    "                                                                                 perm_values.max()))\n",
    "    n_perm = df_perm.shape[0] + 1  # plus the neutral permutation\n",
    "    return (np.sum(perm_values >= real_value) + 1) / n_perm\n",
    "\n",
    "df_result_clf = pd.read_csv('results_classification_with_covariate_regr.csv', index_col=0, \n",
    "                            header=[0, 1])\n",
    "df_result_clf_roi = df_result_clf.loc[['ROI:NAc', 'ROI:ATR', 'ROI:NAc+ATR']]\n",
    "roi_names = ['NAc', 'ATR', 'NAc+ATR']\n",
    "metric_to_use = 'AUC'\n",
    "n_tests = 3\n",
    "\n",
    "print('Metrics to calculate p-value for: {}'.format(metric_to_use))\n",
    "for roi_name in roi_names:\n",
    "    print(roi_name)\n",
    "    df_perm_roi = pd.read_csv('results_perm_classification_{}.csv'.format(roi_name))\n",
    "    p_roi = calculate_permutation_pvalue(df_result_clf_roi.loc['ROI:{}'.format(roi_name)],\n",
    "                                         df_perm_roi, metric_to_use)\n",
    "    print('P-value: {:0.6f}'.format(p_roi))\n",
    "    print('P-value - Bonferroni-corrected for {} tests: {:0.6f}'.format(n_tests, p_roi * n_tests))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
